{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Bayesian Linear Regression  \n",
    "\n",
    "-----------\n",
    "\n",
    "_Author: Khal Makhoul, W.P.G.Peterson_  \n",
    "\n",
    "## Project Guide\n",
    "\n",
    "--------------\n",
    "\n",
    "- [Project Overview](#overview)\n",
    "- [Introduction and Review](#intro)\n",
    "- [Coding Bayesian Linear Regression](#code)\n",
    "- [Data Refresher](#data)\n",
    "\n",
    "<a id = \"overview\"></a>\n",
    "## Project Overview  \n",
    "\n",
    "------------\n",
    "#### EXPECTED TIME 3 HRS\n",
    "\n",
    "This assignment will test your abilities in two different sections: the [review](#intro) section will revisit Bayes' formula and evaluate your ability to calculate simple Bayesian posterior probabilities. The [coding](#code) section will ask you to build functions that calculate the parameters of Bayesian posteriors for Bayesian Linear Regression.  \n",
    "\n",
    "\n",
    "Programming questions will include:\n",
    "- Calculation of Bayesian Posterior\n",
    "- Calculating the $w_{MAP}$\n",
    "- Estimating $\\sigma^2$\n",
    "- Calculating $\\Sigma$  \n",
    "\n",
    "**Motivation**: Bayesian regression allows us to quantify the uncertainty in our model building / the point estimates of our weights calculated in Least Squares Regression.  \n",
    "\n",
    "**Objectives**: This assignment will test fundamental Bayesian knowledge, particulary in regard to Linear Regression\n",
    " \n",
    "\n",
    "**Problem**: Once again we will be using housing data to predict house price using living area and year built.  \n",
    "\n",
    "**Data**: Our data comes from [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). \n",
    "\n",
    "#### Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell imports the necessary modules and sets a few plotting parameters for display\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "<a id = \"intro\"></a>\n",
    "### Introduction and Review.\n",
    "\n",
    "Bayesian Regression comes with a different toolset than ordinary Linear Regression. In turn, that toolset demands a slightly different mindset. We start with a short review to hightlight the ways in which Bayesian thinking proceeds.\n",
    "\n",
    "Consider a population whose age distribution is as follows:\n",
    "\n",
    "| Age group | $\\%$ of total population   |\n",
    "|------|------|\n",
    "|   $\\le 35$  | $25 \\%$|\n",
    "| $36-65$ | $45 \\%$ |\n",
    "| $\\ge 66$ | $30 \\%$|\n",
    "\n",
    "Say you know the following results of a study about YouTube viewing habits:\n",
    "\n",
    "| Age group | $\\%$ in this group that watch YouTube every day  |\n",
    "|------|------|\n",
    "|   $\\le 35$  | $90 \\%$|\n",
    "| $36-65$ | $50 \\%$  |\n",
    "| $\\ge 66$ | $10 \\%$ |\n",
    "\n",
    "**Prompt: If you know a user watches YouTube every day, what is the probability that they are under 35?**\n",
    "\n",
    "\n",
    "We will start with a prior, then update that prior using the likelihood and the normalization from Bayes's formula. We define the following notation:\n",
    "\n",
    "* $A$: YouTube watching habit\n",
    "* $B$: Age\n",
    "* $A = 1$: User watches YouTube every day \n",
    "* $A = 0$: User does not watch YouTube every day\n",
    "* $B \\le 35$: User has age between 0 and 35\n",
    "* $36 \\le B \\le 65$: User has age between 36 and 65\n",
    "* $B \\ge  66$: User has age greater than 65\n",
    "\n",
    "The prior can be read from the first table: \n",
    "\n",
    "$$P(B \\le 35) = 0.25$$\n",
    "\n",
    "We are looking to calculate the posterior probability:\n",
    "\n",
    "$$P(B \\le 35|A = 1)$$\n",
    "\n",
    "With Bayes's formula:\n",
    "\n",
    "$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$$\n",
    "\n",
    "For our question:\n",
    "\n",
    "$$P(B \\le 35|A=1) = \\frac{P(A=1|B \\le 35)*P(B \\le 35)}{P(A=1)}$$  \n",
    "\n",
    "While the tables do not contain the value of $P(A=1)$ it may be calculated:  \n",
    "\n",
    "$P(A=1) = $  \n",
    "\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ P(A=1| B\\le 35)*P(B\\le 35) \\ + $  \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ P(A=1|35<B<65)* P(35<B<65)\\  + $  \n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ P(A=1|B\\ge 65)*P(B\\ge 65)$\n",
    "\n",
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### In the example above, P(A=1|B<35) is the:\n",
    "### 'a')prior\n",
    "### 'b')liklihood\n",
    "### 'c')nomalization\n",
    "### 'd')posterior\n",
    "\n",
    "### assign character associated with your choice as string to ans1\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans1 = 'b'\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 1",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46875000000000006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_A = 0.48 #PROBABILIDAD QUE ALGUIEN VEA YOUTUBE TODOS LOS DIAS\n",
    "P_B = 0.25 #PROBABILIDAD DE QUE ALGUIEN TENGA/SEA MENOR O IGUAL A 35 AÑOS (PRIOR)\n",
    "P_AnB = 0.9 #PROBABILIDAD DE QUE ALGIEN MENOR O IGUAL A 35 AÑOS VEA YOUTUBE (LIKEHOOD)\n",
    "\n",
    "#PROBABILIDAD DE QUE SELECCIONANDO AL AZAR A ALGUIEN QUE VEA YOUTUBE, TENGA/SEA MENOR O IGUAL A 35 AÑOS (POSTERIOR)\n",
    "P_BnA = (P_AnB * P_B)/P_A\n",
    "P_BnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Given the values in the tables above, calculate the posterior for:\n",
    "\n",
    "### \"If you know a user watches Youtube every day,\n",
    "### what is the probability that they are under 35?\"\n",
    "\n",
    "### Assign float (posterior probability between 0 and 1) to ans1\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans1 = 0.46875\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_posterior(likelihood, prior, norm_list):\n",
    "    #Naming convetion: P(B|A) = P(A|B)P(B)/P(A)\n",
    "    \n",
    "    ##Calculation of Normalization factor ...\n",
    "    norm_fac = []\n",
    "    ##List element arrangement is: (P(B),P(A|B)) ...\n",
    "    for p in norm_list:\n",
    "        P_B,P_AnB = p\n",
    "        norm_fac.append(P_AnB*P_B)\n",
    "        \n",
    "    #Marginal ...\n",
    "    P_A = sum(norm_fac)\n",
    "    ##Likelihood ...\n",
    "    P_AnB = likelihood\n",
    "    ##Prior ...\n",
    "    P_B = prior\n",
    "    \n",
    "    return (P_AnB*P_B)/P_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45714285714285713\n"
     ]
    }
   ],
   "source": [
    "likelihood = .8\n",
    "prior = .3\n",
    "norm_list = [(.25 , .9), (.5, .5), (.25,.2)]\n",
    "print(calc_posterior(likelihood, prior, norm_list))\n",
    "# --> 0.45714285714285713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called `calc_posterior`\n",
    "\n",
    "### ACCEPT three inputs\n",
    "### Two floats: the likelihood and the prior\n",
    "### One list of tuples, where each tuple has two values corresponding to:\n",
    "### ### ( P(Bn) , P(A|Bn) )\n",
    "### ### ### Assume the list of tuples accounts for all potential values of B\n",
    "### ### ### And that those values of B are all mutually exclusive.\n",
    "### The list of tuples allows for the calculation of normalization constant.\n",
    "\n",
    "### RETURN a float corresponding to the posterior probability\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def calc_posterior(likelihood, prior, norm_list):\n",
    "    \"\"\"\n",
    "    Calculate the posterior probability given likelihood,\n",
    "    prior, and normalization\n",
    "    \n",
    "    Positional Arguments:\n",
    "        likelihood -- float, between 0 and 1\n",
    "        prior -- float, between 0 and 1\n",
    "        norm_list -- list of tuples, each tuple has two values\n",
    "            the first value corresponding to the probability of a value of \"b\"\n",
    "            the second value corresponding to the probability of \n",
    "                a value of \"a\" given that value of \"b\"\n",
    "    Example:\n",
    "        likelihood = .8\n",
    "        prior = .3\n",
    "        norm_list = [(.25 , .9), (.5, .5), (.25,.2)]\n",
    "        print(calc_posterior(likelihood, prior, norm_list))\n",
    "        # --> 0.45714285714285713\n",
    "    \"\"\"\n",
    "    #Naming convetion: P(B|A) = P(A|B)P(B)/P(A)\n",
    "    \n",
    "    ##Calculation of Normalization factor ...\n",
    "    norm_fac = []\n",
    "    ##List element arrangement is: (P(B),P(A|B)) ...\n",
    "    for p in norm_list:\n",
    "        P_B,P_AnB = p\n",
    "        norm_fac.append(P_AnB*P_B)\n",
    "        \n",
    "    #Marginal ...\n",
    "    P_A = sum(norm_fac)\n",
    "    ##Likelihood ...\n",
    "    P_AnB = likelihood\n",
    "    ##Prior ...\n",
    "    P_B = prior\n",
    "    \n",
    "    return (P_AnB*P_B)/P_A \n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 3",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Applicability\n",
    "\n",
    "In real life, this situation corresponds to:  \n",
    "1. Surveying people and asking them two questions (what's your age? do you watch YouTube every day?), then tabulating the percentage of each age group that watch YouTube everyday.\n",
    "2. After having collected that data, observing the anonymized watching habits of a set of different users (not the survey takers) - without access to additional demographic info -  and using the above survey to derive a probability for the anonymized users' age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Bayesian Linear Regression\n",
    "\n",
    "In Bayesian Linear Regression, our prior expresses a belief about the parameters of linear regression we wish to calculate, namely that the linear coefficient vector should have a small absolute value, and that deviations from zero should be Gaussian. This prior is mathematically equivalent to the Ridge Regression condition.\n",
    "\n",
    "So the question we will now ask is: conditioned on the data, how does our belief regarding the parameters of linear regression change? \n",
    "\n",
    "This is the same prior-to-posterior calculation of the above exercise.  \n",
    "\n",
    "Bayes' Rule:\n",
    "\n",
    "$P(B|A) = \\frac{P(A|B)\\ P(B)}{P(A)}$,\n",
    "\n",
    "For linear Regression:\n",
    "\n",
    "$p(w | y, X) = \\frac{p(y | w, X)\\ p(w)}{p(y | X)}$  \n",
    "\n",
    "What do we know, and what do we not know?\n",
    "\n",
    "* $p(w) = N(0, \\lambda^{-1} I)$: That's the prior on $w$ --- Known.  \n",
    "\n",
    "\n",
    "* $p(y | w, X) = N(X w, \\sigma^2 I)$: That's the likelihood expression --- Known.  \n",
    "\n",
    "\n",
    "* $p(y | X)$: That's the marginal probability of $y$ --- NOT KNOWN\n",
    "\n",
    "Rewriting the marginal probability in detail, using an integral instead of a sum - since $w$ is a continuous variable.\n",
    "\n",
    "$p(y | X) = \\int_{\\mathbb{R^d}} p(y, w | X)\\ dw$\n",
    "\n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = \\int_{\\mathbb{R^d}}\\ p(y | w, X)\\  p(w)\\ dw$\n",
    "\n",
    "\n",
    "At this point approximation is frequently required as the above integral usually has no closed form.  \n",
    "\n",
    "<a id= \"code\"></a>\n",
    "\n",
    "### Coding Bayesian Linear Regression\n",
    "\n",
    "In lecture, we obtained an equation for the posterior probability of $w$, the linear regression parameter vector:\n",
    "\n",
    "$$p(w|y, X) = N(w|\\mu, \\Sigma)$$\n",
    "\n",
    "#### where\n",
    "\n",
    "$$\\Sigma = (\\lambda \\ I + \\sigma^{- 2}\\ X^T\\ X)^{−1}$$\n",
    "\n",
    "$$\\mu = (\\lambda \\ \\sigma^2 I + X^T\\ X)^{-1}\\ X^T y ⇐ w_{MAP}$$\n",
    "\n",
    "\n",
    "\n",
    "Recall that $\\sigma^2$ is a parameter characterizing the deviation of the data from the line defined by $Xw$. While we don't know the true underlying parameter, we can estimate it by using the empirical deviation:\n",
    "\n",
    "$$\\sigma^2 \\approx \\hat{\\sigma}^2 = \\frac{1}{n − d}\\Sigma_{i=1}^n ( y_i − X_i w )^2$$  \n",
    "Where $w$ in the above is the $w_{LeastSquares} = (X^T\\ X)^{-1}\\ X^T y$\n",
    "\n",
    "\n",
    "-----------------------\n",
    "When it comes to prediction:  \n",
    "$p( y_0|x_0,y,X) = N(y_0|\\mu_0,\\sigma^2_0)$  \n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\mu_0 = x^T_0\\mu$  \n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sigma^2_0 = \\sigma^2 + x_0^T\\Sigma x_0$  \n",
    "\n",
    "-----------------------------\n",
    "This section will involve coding five functions:\n",
    "- `x_preprocess`\n",
    "- `calculate_map_coefficients`\n",
    "- `estimate_data_noise`\n",
    "- `calc_post_cov_mtx`\n",
    "- `predict` \n",
    "\n",
    "Such that the functions `fit_bayes_reg` and `predict_bayes_reg` - outlined below - will work correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_bayes_reg(input_x, output_y, lambda_param):\n",
    "    \n",
    "    # Ensure correct shape of X, add column of 1's for intercept\n",
    "    aug_x = x_preprocess(input_x) # <----\n",
    "    \n",
    "    # Calculate least-squares weights\n",
    "    ml_weights = calculate_map_coefficients(aug_x, output_y, 0, 0) # <----\n",
    "        \n",
    "    # Estimate sigma^2 from observations\n",
    "    sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights) # <----\n",
    "    \n",
    "    # Calculate MAP weights\n",
    "    weights = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared) # <---- \n",
    "\n",
    "    \n",
    "    # Create posterior covariance matrix\n",
    "    big_sig = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param) # <----\n",
    "    \n",
    "    return weights, big_sig\n",
    "\n",
    "def predict_bayes_reg(x_obs, weights, big_sig):\n",
    "    \n",
    "    # Ensure correct shape of X, add 1's for intercept\n",
    "    aug_x = x_preprocess(x_obs) # <----\n",
    "    \n",
    "    # find mean / variance parameters describing prediction for data\n",
    "    mu_0, sig_sq_0 = predict(aug_x, weights, big_sig) # <----\n",
    "    \n",
    "    return mu_0, sig_sq_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: X-matrix preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud Shape:  2 Tamaño Array:  (2, 4)\n",
      "\n",
      "Longitud Shape:  1 Tamaño Array:  (3,)\n"
     ]
    }
   ],
   "source": [
    "##AL CALCULAR LA LONGITUD/NUMERO DE ELEMENTOS EN <.shape> SE OBTIENE EL NUMERO DE DIMENSIONES DEL ARRAY\n",
    "input1 = np.array([[2,3,6,9],[4,5,7,10]])\n",
    "input2 = np.array([2,3,6])\n",
    "\n",
    "print('Longitud Shape: ',len(input1.shape),'Tamaño Array: ',input1.shape)\n",
    "print()\n",
    "print('Longitud Shape: ',len(input2.shape),'Tamaño Array: ',input2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_preprocess(input_x):\n",
    "    ##Check number of array dimensions ...\n",
    "    dim = len(input_x.shape)\n",
    "    \n",
    "    ##If array is a Matrix, Matrix Validation: X_nxp, Where n>>p ...\n",
    "    if dim > 1:\n",
    "        if input_x.shape[0] < input_x.shape[1]:\n",
    "            input_x = input_x.T\n",
    "            \n",
    "        ##Append one's column in X for Intercepto Estimation ...    \n",
    "        betta = np.ones(input_x.shape[0]).T\n",
    "        input_x = np.insert(input_x, 0, betta, axis = 1)\n",
    "        \n",
    "    else:\n",
    "        ##Append 1 to the input vector for Intercepto Estimation ...\n",
    "        input_x = np.insert(input_x, 0, 1)\n",
    "        \n",
    "    return input_x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  4]\n",
      " [ 1  3  5]\n",
      " [ 1  6  7]\n",
      " [ 1  9 10]] \n",
      "\n",
      "[1 2 3 6] \n",
      "\n",
      "[[ 1  2  4]\n",
      " [ 1  3  5]\n",
      " [ 1  6  7]\n",
      " [ 1  9 10]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input1 = np.array([[2,3,6,9],[4,5,7,10]])\n",
    "input2 = np.array([2,3,6])\n",
    "input3 = np.array([[2,4],[3,5],[6,7],[9,10]])\n",
    "\n",
    "for i in [input1, input2, input3]:\n",
    "    print(x_preprocess(i), \"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 1.  2.  4.]\n",
    "[ 1.  3.  5.]\n",
    "[ 1.  6.  7.]\n",
    "[ 1.  9. 10.]] \n",
    "\n",
    "[1 2 3 6] \n",
    "\n",
    "[[ 1.  2.  4.]\n",
    " [ 1.  3.  5.]\n",
    " [ 1.  6.  7.]\n",
    " [ 1.  9. 10.]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Build a function called \"x_preprocess\"\n",
    "### ACCEPT one input, a numpy array\n",
    "### ### Array may be one or two dimensions\n",
    "\n",
    "### If input is two dimensional, make sure there are more rows than columns\n",
    "### ### Then prepend a column of ones for intercept term\n",
    "### If input is one-dimensional, prepend a one\n",
    "\n",
    "### RETURN a numpy array, prepared as described above,\n",
    "### which is now ready for matrix multiplication with regression weights\n",
    "\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def x_preprocess(input_x):\n",
    "    \"\"\"\n",
    "    Reshape the input (if needed), and prepend a \"1\" to every observation\n",
    "    \n",
    "    Positional Argument:\n",
    "        input_x -- a numpy array, one- or two-dimensional\n",
    "    \n",
    "    Example:\n",
    "        input1 = np.array([[2,3,6,9],[4,5,7,10]])\n",
    "        input2 = np.array([2,3,6])\n",
    "        input3 = np.array([[2,4],[3,5],[6,7],[9,10]])\n",
    "        \n",
    "        for i in [input1, input2, input3]:\n",
    "            print(x_preprocess(i), \"\\n\")\n",
    "            \n",
    "        # -->[[ 1.  2.  4.]\n",
    "              [ 1.  3.  5.]\n",
    "              [ 1.  6.  7.]\n",
    "              [ 1.  9. 10.]] \n",
    "\n",
    "            [1 2 3 6] \n",
    "\n",
    "            [[ 1.  2.  4.]\n",
    "             [ 1.  3.  5.]\n",
    "             [ 1.  6.  7.]\n",
    "             [ 1.  9. 10.]] \n",
    "\n",
    "    Assumptions:\n",
    "        Assume that if the input is two dimensional, that the observations are more numerous\n",
    "            than the features, and thus, the observations should be the rows, and features the columns\n",
    "    \"\"\"\n",
    "    ##Check number of array dimensions ...\n",
    "    dim = len(input_x.shape)\n",
    "    \n",
    "    ##If array is a Matrix, Matrix Validation: X_nxp, Where n>>p ...\n",
    "    if dim > 1:\n",
    "        if input_x.shape[0] < input_x.shape[1]:\n",
    "            input_x = input_x.T\n",
    "            \n",
    "        ##Append one's column in X for Intercepto Estimation ...    \n",
    "        betta = np.ones(input_x.shape[0]).T\n",
    "        input_x = np.insert(input_x, 0, betta, axis = 1)\n",
    "        \n",
    "    else:\n",
    "        ##Append 1 to the input vector for Intercepto Estimation ...\n",
    "        input_x = np.insert(input_x, 0, 1)\n",
    "        \n",
    "    return input_x\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 4",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 5: MAP Coefficients:\n",
    "\n",
    "$$\\mu = (\\lambda \\ \\sigma^2 I + X^T\\ X)^{-1}\\ X^T y = w_{MAP}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared):\n",
    "    \n",
    "    ##Getting the shift matrix ...\n",
    "    Ls = lambda_param * sigma_squared * np.identity(aug_x.shape[1])\n",
    "    ##Inverse shifted matrix: (lambda*sigma^2*I + X.T*X)^-1 ...\n",
    "    X_inv = np.linalg.inv(Ls + np.matmul(aug_x.T,aug_x))\n",
    "    ##Premultiplied matrix:(lambda*sigma^2*I + X.T*X)^-1 * X.T\n",
    "    left_matrix = np.matmul(X_inv, aug_x.T)\n",
    "    ##Weights calculation: w = (lambda*sigma^2*I + X.T*X)^-1 * X.T * y\n",
    "    weights = np.matmul(left_matrix, output_y)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-576.67947106   77.45913349   31.50189177]\n",
      "[-2.29223802e+06  5.92536529e+01  1.20780450e+03]\n"
     ]
    }
   ],
   "source": [
    "output_y = np.array([208500, 181500, 223500, \n",
    "                     140000, 250000, 143000, \n",
    "                     307000, 200000, 129900, \n",
    "                     118000])\n",
    "aug_x = np. array([[   1., 1710., 2003.],\n",
    "                   [   1., 1262., 1976.],\n",
    "                   [   1., 1786., 2001.],\n",
    "                   [   1., 1717., 1915.],\n",
    "                   [   1., 2198., 2000.],\n",
    "                   [   1., 1362., 1993.],\n",
    "                   [   1., 1694., 2004.],\n",
    "                   [   1., 2090., 1973.],\n",
    "                   [   1., 1774., 1931.],\n",
    "                   [   1., 1077., 1939.]])\n",
    "lambda_param = 0.01\n",
    "sigma_squared = 1000\n",
    "\n",
    "map_coef = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "ml_coef = calculate_map_coefficients(aug_x, output_y, 0,0) #Least Squares Coefficients!!!!\n",
    "\n",
    "print(map_coef)\n",
    "# --> np.array([-576.67947107   77.45913349   31.50189177])\n",
    "print(ml_coef)\n",
    "#--> np.array([-2.29223802e+06  5.92536529e+01  1.20780450e+03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Build a function called `calculate_map_coefficients`\n",
    "\n",
    "### ACCEPT four inputs:\n",
    "### Two numpy arrays; an X-matrix and y-vector\n",
    "### Two positive numbers, a lambda parameter, and value for sigma^2\n",
    "\n",
    "### RETURN a 1-d numpy vector of weights.\n",
    "\n",
    "### ASSUME your x-matrix has been preprocessed:\n",
    "### observations are in rows, features in columns, and a column of 1's prepended.\n",
    "\n",
    "### Use the above equation to calculate the MAP weights.\n",
    "### ### This will involve creating the lambda matrix.\n",
    "### ### The MAP weights are equal to the Ridge Regression weights\n",
    "\n",
    "### NB: `.shape`, `np.matmul`, `np.linalg.inv`,\n",
    "### `np.ones`, `np.identity` and `np.transpose` will be valuable.\n",
    "\n",
    "### If either the \"sigma_squared\" or \"lambda_param\" are equal to 0, the return will be\n",
    "### equivalent to ordinary least squares.\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared):\n",
    "    \"\"\"\n",
    "    Calculate the maximum a posteriori LR parameters\n",
    "    \n",
    "     Positional arguments:\n",
    "        aug_x -- x-matrix of training input data, augmented with column of 1's\n",
    "        output_y -- vector of training output values\n",
    "        lambda_param -- positive number; lambda parameter that\n",
    "            controls how heavily to penalize large coefficient values\n",
    "        sigma_squared -- data noise estimate\n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                             140000, 250000, 143000, \n",
    "                             307000, 200000, 129900, \n",
    "                             118000])\n",
    "                             \n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "                           \n",
    "        lambda_param = 0.01\n",
    "        \n",
    "        sigma_squared = 1000\n",
    "        \n",
    "        map_coef = calculate_map_coefficients(aug_x, output_y, \n",
    "                                             lambda_param, sigma_squared)\n",
    "                                             \n",
    "        ml_coef = calculate_map_coefficients(aug_x, output_y, 0,0)\n",
    "        \n",
    "        print(map_coef)\n",
    "        # --> np.array([-576.67947107   77.45913349   31.50189177])\n",
    "        \n",
    "        print(ml_coef)\n",
    "        #--> np.array([-2.29223802e+06  5.92536529e+01  1.20780450e+03])\n",
    "        \n",
    "    Assumptions:\n",
    "        -- output_y is a vector whose length is the same as the\n",
    "        number of rows in input_x\n",
    "        -- aug_x has more observations than it does features.\n",
    "        -- lambda_param has a value greater than 0\n",
    "    \"\"\"\n",
    "    ##Getting the shift matrix ...\n",
    "    Ls = lambda_param * sigma_squared * np.identity(aug_x.shape[1])\n",
    "    ##Inverse shifted matrix: (lambda*sigma^2*I + X.T*X)^-1 ...\n",
    "    X_inv = np.linalg.inv(Ls + np.matmul(aug_x.T,aug_x))\n",
    "    ##Premultiplied matrix:(lambda*sigma^2*I + X.T*X)^-1 * X.T\n",
    "    left_matrix = np.matmul(X_inv, aug_x.T)\n",
    "    ##Weights calculation: w = (lambda*sigma^2*I + X.T*X)^-1 * X.T * y\n",
    "    weights = np.matmul(left_matrix, output_y)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 5",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 6: Estimate Data Noise\n",
    "$$\\sigma^2 \\approx \\hat{\\sigma}^2 = \\frac{1}{n − d}\\Sigma_{i=1}^n ( y_i − X_i w )^2$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_data_noise(aug_x, output_y, weights):\n",
    "    \n",
    "    ##Getting number of Observations and Features ...\n",
    "    npoints, dim = aug_x.shape\n",
    "    \n",
    "    ##Calculating SSE (Deviations from Line's Model) ...\n",
    "    SSE = []\n",
    "    for n in range(len(output_y)):\n",
    "        SSE.append((output_y[n] - np.matmul(aug_x[n,:],weights.T))**2)\n",
    "        \n",
    "    SSE = sum(SSE)\n",
    "    \n",
    "    ##Calculating model noise ...\n",
    "    noise = SSE/(npoints - dim)\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.29223802e+06  5.92536529e+01  1.20780450e+03]\n",
      "1471223687.159289\n"
     ]
    }
   ],
   "source": [
    "output_y = np.array([208500, 181500, 223500, \n",
    "                        140000, 250000, 143000, \n",
    "                        307000, 200000, 129900, \n",
    "                        118000])\n",
    "aug_x = np. array([[   1., 1710., 2003.],\n",
    "                   [   1., 1262., 1976.],\n",
    "                   [   1., 1786., 2001.],\n",
    "                   [   1., 1717., 1915.],\n",
    "                   [   1., 2198., 2000.],\n",
    "                   [   1., 1362., 1993.],\n",
    "                   [   1., 1694., 2004.],\n",
    "                   [   1., 2090., 1973.],\n",
    "                   [   1., 1774., 1931.],\n",
    "                   [   1., 1077., 1939.]])\n",
    "\n",
    "ml_weights = calculate_map_coefficients(aug_x, output_y, 0, 0) #Least Squares Coefficients!!!!\n",
    "print(ml_weights)\n",
    "# --> [-2.29223802e+06  5.92536529e+01  1.20780450e+03]\n",
    "\n",
    "sig2 = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "print(sig2)\n",
    "# #--> 1471223687.1593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called `esimate_data_noise`\n",
    "\n",
    "### ACCEPT three inputs, all numpy arrays\n",
    "### One matrix coresponding to the augmented x-matrix\n",
    "### Two vectors, one of the y-target, and one of ML weights.\n",
    "\n",
    "### RETURN the empirical data noise estimate: sigma^2. Calculated with equation given above.\n",
    "\n",
    "### NB: \"n\" is the number of observations in X (rows)\n",
    "### \"d\" is the number of features in aug_x (columns) \n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def estimate_data_noise(aug_x, output_y, weights):\n",
    "    \"\"\"Return empirical data noise estimate \\sigma^2\n",
    "    Use the LR weights in the equation supplied above\n",
    "    \n",
    "    Positional arguments:\n",
    "        aug_x -- matrix of training input data\n",
    "        output_y -- vector of training output values\n",
    "        weights -- vector of LR weights calculated from output_y and aug_x\n",
    "        \n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "        \n",
    "        ml_weights = calculate_map_coefficients(aug_x, output_y, 0, 0)\n",
    "        \n",
    "        print(ml_weights)\n",
    "        # --> [-2.29223802e+06  5.92536529e+01  1.20780450e+03]\n",
    "        \n",
    "        sig2 = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "        print(sig2)\n",
    "        #--> 1471223687.1593\n",
    "        \n",
    "    Assumptions:\n",
    "        -- aug_x has more observations than it does features.\n",
    "        -- output_y is a vector whose length is the same as the\n",
    "        number of rows in training_x\n",
    "    \"\"\"\n",
    "    ##Getting number of Observations and Features ...\n",
    "    npoints, dim = aug_x.shape\n",
    "    \n",
    "    ##Calculating SSE (Deviations from Line's Model) ...\n",
    "    SSE = []\n",
    "    for n in range(len(output_y)):\n",
    "        SSE.append((output_y[n] - np.matmul(aug_x[n,:],weights.T))**2)\n",
    "        \n",
    "    SSE = sum(SSE)\n",
    "    \n",
    "    ##Calculating model noise ...\n",
    "    noise = SSE/(npoints - dim)\n",
    "    \n",
    "    return noise\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 6",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 7: Posterier Covariance  \n",
    "\n",
    "$$\\Sigma = (\\lambda \\ I + \\sigma^{- 2}\\ X^T\\ X)^{−1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_post_cov_mtx(aug_x, sigma_squared, lambda_param):\n",
    "    \n",
    "    ##Getting the shift matrix ...\n",
    "    Ls = lambda_param * np.identity(aug_x.shape[1])\n",
    "    ##Getting X matrix normalized by sigma^2: X.T*X/sigma^2 ...\n",
    "    X_norm = np.matmul(aug_x.T,aug_x)/sigma_squared\n",
    "    ##Covariance matrix calculation: (lambda*I + X.T*X/sigma^2)^-1 ...\n",
    "    S = np.linalg.inv(Ls + X_norm)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.99999874e+01 -1.95016334e-02 -2.48082095e-02]\n",
      " [-1.95016334e-02  6.28700339e+01 -3.85675510e+01]\n",
      " [-2.48082095e-02 -3.85675510e+01  5.10719826e+01]]\n"
     ]
    }
   ],
   "source": [
    "output_y = np.array([208500, 181500, 223500, \n",
    "                    140000, 250000, 143000, \n",
    "                    307000, 200000, 129900, \n",
    "                    118000])\n",
    "aug_x = np. array([[   1., 1710., 2003.],\n",
    "               [   1., 1262., 1976.],\n",
    "               [   1., 1786., 2001.],\n",
    "               [   1., 1717., 1915.],\n",
    "               [   1., 2198., 2000.],\n",
    "               [   1., 1362., 1993.],\n",
    "               [   1., 1694., 2004.],\n",
    "               [   1., 2090., 1973.],\n",
    "               [   1., 1774., 1931.],\n",
    "               [   1., 1077., 1939.]])\n",
    "lambda_param = 0.01\n",
    "ml_weights = calculate_map_coefficients(aug_x, output_y,0,0)\n",
    "sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "print(calc_post_cov_mtx(aug_x, sigma_squared, lambda_param))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 9.99999874e+01 -1.95016334e-02 -2.48082095e-02]\n",
    "[-1.95016334e-02  6.28700339e+01 -3.85675510e+01]\n",
    "[-2.48082095e-02 -3.85675510e+01  5.10719826e+01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"calc_post_cov_mtx\"\n",
    "### ACCEPT three inputs:\n",
    "### One numpy array for the augmented x-matrix\n",
    "### Two floats for sigma-squared and a lambda_param\n",
    "\n",
    "### Calculate the covariance matrix of the posterior (capital sigma), via equation given above.\n",
    "### RETURN that matrix.\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "\n",
    "def calc_post_cov_mtx(aug_x, sigma_squared, lambda_param):\n",
    "    \"\"\"\n",
    "    Calculate the covariance of the posterior for Bayesian parameters\n",
    "    \n",
    "    Positional arguments:\n",
    "        aug_x -- matrix of training input data; preprocessed\n",
    "        sigma_squared -- estimation of sigma^2\n",
    "        lambda_param -- lambda parameter that controls how heavily\n",
    "        to penalize large weight values\n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "        lambda_param = 0.01\n",
    "        \n",
    "        ml_weights = calculate_map_coefficients(aug_x, output_y,0,0)\n",
    "        \n",
    "        sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "        \n",
    "        print(calc_post_cov_mtx(aug_x, sigma_squared, lambda_param))\n",
    "        # --> [[ 9.99999874e+01 -1.95016334e-02 -2.48082095e-02]\n",
    "               [-1.95016334e-02  6.28700339e+01 -3.85675510e+01]\n",
    "               [-2.48082095e-02 -3.85675510e+01  5.10719826e+01]]\n",
    "\n",
    "    Assumptions:\n",
    "        -- aug_x is a vector whose length is the same as the\n",
    "        number of rows in training_x\n",
    "        -- lambda_param has a value greater than 0\n",
    "    \n",
    "    \"\"\"\n",
    "    ##Getting the shift matrix ...\n",
    "    Ls = lambda_param * np.identity(aug_x.shape[1])\n",
    "    ##Getting X matrix normalized by sigma^2: X.T*X/sigma^2 ...\n",
    "    X_norm = np.matmul(aug_x.T,aug_x)/sigma_squared\n",
    "    ##Covariance matrix calculation: (lambda*I + X.T*X/sigma^2)^-1 ...\n",
    "    S = np.linalg.inv(Ls + X_norm)\n",
    "    \n",
    "    return S\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 7",
     "locked": true,
     "points": "20",
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now we have functions for\n",
    "$$\\Sigma = (\\lambda \\ I + \\sigma^{- 2}\\ X^T\\ X)^{−1}$$\n",
    "$$\\mu = w_{map}=(\\lambda\\ \\sigma^2 I+X^TX)^{-1}X^Ty$$\n",
    "\n",
    "And thus, $p(w|y, X) = N(w|\\mu, \\Sigma)$, the posterior distribution of the linear regression parameters may be described.\n",
    "\n",
    "When we want to predict an unknown value, $y_0$ given observations $x_0$:  \n",
    "$p( y_0|x_0,y,X) = N(y_0|\\mu_0,\\sigma^2_0)$  \n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\mu_0 = x^T_0\\mu$  \n",
    "$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sigma^2_0 = \\sigma^2 + x_0^T\\Sigma x_0$  \n",
    "\n",
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict( aug_x, weights, big_sig, sigma_squared):\n",
    "    ##Prediction, p(y0|x0,y,X) ~ N(y0|mu_0,sig_0^2)\n",
    "    \n",
    "    ##Calculating mean value for the prediction ...\n",
    "    mu_0 = np.matmul(aug_x.T,weights)\n",
    "    ##Calculating the variance for the prediction ...\n",
    "    sig_0_2 = sigma_squared + np.matmul(aug_x.T, np.matmul(big_sig,aug_x))\n",
    "    \n",
    "    return mu_0,sig_0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158741.63066087314, 1593503867.9059994)\n"
     ]
    }
   ],
   "source": [
    "output_y = np.array([208500, 181500, 223500, \n",
    "                        140000, 250000, 143000, \n",
    "                        307000, 200000, 129900, \n",
    "                        118000])\n",
    "\n",
    "aug_x = np. array([[   1., 1710., 2003.],\n",
    "                   [   1., 1262., 1976.],\n",
    "                   [   1., 1786., 2001.],\n",
    "                   [   1., 1717., 1915.],\n",
    "                   [   1., 2198., 2000.],\n",
    "                   [   1., 1362., 1993.],\n",
    "                   [   1., 1694., 2004.],\n",
    "                   [   1., 2090., 1973.],\n",
    "                   [   1., 1774., 1931.],\n",
    "                   [   1., 1077., 1939.]])\n",
    "lambda_param = 0.01\n",
    "ml_weights = calculate_map_coefficients(aug_x, output_y,0,0)\n",
    "sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "map_weights = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "big_sig = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param)\n",
    "to_pred2 = np.array([1,1700,1980])\n",
    "\n",
    "print(predict(to_pred2, map_weights, big_sig, sigma_squared))\n",
    "#-->(158741.6306608729, 1593503867.9060116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"predict\"\n",
    "### ACCEPT four inputs, three numpy arrays, and one number:\n",
    "### A 1-dimensional array corresponding to an augmented_x vector.\n",
    "### A vector corresponding to the MAP weights, or \"mu\"\n",
    "### A square matrix for the \"big_sigma\" term\n",
    "### A positive number for the \"sigma_squared\" term\n",
    "\n",
    "### Using the above equations\n",
    "\n",
    "### RETURN mu_0 and sigma_squared_0 - a point estimate and variance\n",
    "### for the prediction for x.\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def predict( aug_x, weights, big_sig, sigma_squared):\n",
    "    \"\"\"\n",
    "    Calculate point estimates and uncertainty for new values of x\n",
    "    \n",
    "    Positional Arguments:\n",
    "        aug_x -- augmented matrix of observations for predictions\n",
    "        weights -- MAP weights calculated from Bayesian LR\n",
    "        big_sig -- The posterior covarience matrix, from Bayesian LR\n",
    "        sigma_squared -- The observed uncertainty in Bayesian LR\n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "                                \n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "        lambda_param = 0.01\n",
    "        \n",
    "        ml_weights = calculate_map_coefficients(aug_x, output_y,0,0)\n",
    "        \n",
    "        sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "        \n",
    "        map_weights = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "        \n",
    "        big_sig = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param)\n",
    "        \n",
    "        to_pred2 = np.array([1,1700,1980])\n",
    "        \n",
    "        print(predict(to_pred2, map_weights, big_sig, sigma_squared))\n",
    "        #-->(158741.6306608729, 1593503867.9060116)\n",
    "        \n",
    "    \"\"\"\n",
    "    ##Prediction, p(y0|x0,y,X) ~ N(y0|mu_0,sig_0^2)\n",
    "    \n",
    "    ##Calculating mean value for the prediction ...\n",
    "    mu_0 = np.matmul(aug_x.T,weights)\n",
    "    ##Calculating the variance for the prediction ...\n",
    "    sig_0_2 = sigma_squared + np.matmul(aug_x.T, np.matmul(big_sig,aug_x))\n",
    "    \n",
    "    return mu_0,sig_0_2\n",
    "\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 8",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"data\"></a>\n",
    "### Data Refresher  \n",
    "\n",
    "Once again, we will be using the Bayesian regression functions on house price data. Observations from this data will be used to test the functions you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Read in the data\n",
    "tr_path = '../resource/asnlib/publicdata/train.csv'\n",
    "data = pd.read_csv(tr_path)  \n",
    "\n",
    "### The .head() function shows the first few lines of data for perspecitve\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read in the data\n",
    "tr_path = 'train.csv'\n",
    "data = pd.read_csv(tr_path)  \n",
    "\n",
    "### The .head() function shows the first few lines of data for perspecitve\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot('GrLivArea', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot('YearBuilt', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 9: On Housing Data\n",
    "\n",
    "Use your functions above to return a $\\Sigma$ and $\\mu$ for our housing dataset.\n",
    "\n",
    "Use \"SalePrice\" as the target, and \"GrLivArea\" and \"YearBuilt\" as predictors. Keep \"GrLivArea\" and \"YearBuild\", in that order. (Order is important for grading.)  \n",
    "\n",
    "**USE ALL OBSERVATIONS IN `data` NOT JUST THE FIRST 100 AS IS DONE IN THE EXAMPLE**\n",
    "\n",
    "e.g.\n",
    "```\n",
    "input_x = data[['GrLivArea, 'YearBuilt']].values\n",
    "```\n",
    "\n",
    "Use .1 for $\\lambda$ \n",
    "\n",
    "Below, return the $\\mu$ vector to the variable \"mu\"  \n",
    "\n",
    "Return the $\\Sigma$ matrix to the variable \"big_sig\"\n",
    "\n",
    "Remember, the `fit_bayes_reg` function should work if you defined the above equations correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.10423243e-02 4.10449281e+01 4.22635006e+01]\n",
      "\n",
      "[[ 9.99999861e+00 -1.75179751e-03 -2.74204060e-03]\n",
      " [-1.75179751e-03  6.50420674e+00 -3.47271893e+00]\n",
      " [-2.74204060e-03 -3.47271893e+00  4.60297584e+00]]\n"
     ]
    }
   ],
   "source": [
    "input_x = data[['GrLivArea','YearBuilt']].head(100).values ##REGRESA SOLO LOS VALORES COMO UN NUMPY-ARRAY!!!\n",
    "output_y = data['SalePrice'].head(100).values ##REGRESA SOLO LOS VALORES COMO UN NUMPY-ARRAY!!!\n",
    "lambda_param = .1\n",
    "# < --- CODE BLOCK --->\n",
    "aug_x = x_preprocess(input_x)\n",
    "w_ls = calculate_map_coefficients(aug_x, output_y, 0,0) ##Least Squares Coefficients!!!\n",
    "sigma_squared = estimate_data_noise(aug_x, output_y, w_ls)\n",
    "mu = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "big_sig = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param)\n",
    "\n",
    "print(mu)\n",
    "print()\n",
    "print(big_sig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[2.10423243e-02, 4.10449281e+01, 4.22635006e+01]\n",
    "\n",
    "[[ 9.99999861e+00, -1.75179751e-03, -2.74204060e-03],\n",
    "[-1.75179751e-03,  6.50420674e+00, -3.47271893e+00],\n",
    "[-2.74204060e-03, -3.47271893e+00,  4.60297584e+00]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = data[['GrLivArea','YearBuilt']].values\n",
    "output_y = data['SalePrice'].values\n",
    "lambda_param = .1\n",
    "# < --- CODE BLOCK --->\n",
    "aug_x = x_preprocess(input_x)\n",
    "w_ls = calculate_map_coefficients(aug_x, output_y, 0,0) ##Least Squares Coefficients!!!\n",
    "sigma_squared = estimate_data_noise(aug_x, output_y, w_ls)\n",
    "\n",
    "w_map = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "S = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow directions above\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "\"\"\"\n",
    "Example:\n",
    "    input_x = data[['GrLivArea','YearBuilt']].head(100).values\n",
    "    output_y = data['SalePrice'].head(100).values\n",
    "    lambda_param = .1\n",
    "    \n",
    "    < --- CODE BLOCK --->\n",
    "    \n",
    "    print(mu)\n",
    "    #--> np.array([2.10423243e-02, 4.10449281e+01, 4.22635006e+01])\n",
    "    print(big_sig)\n",
    "    #--> \n",
    "    np.array([[ 9.99999861e+00, -1.75179751e-03, -2.74204060e-03],\n",
    "              [-1.75179751e-03,  6.50420674e+00, -3.47271893e+00],\n",
    "              [-2.74204060e-03, -3.47271893e+00,  4.60297584e+00]])\n",
    "\"\"\"\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "input_x = data[['GrLivArea','YearBuilt']].values\n",
    "output_y = data['SalePrice'].values\n",
    "lambda_param = .1\n",
    "# < --- CODE BLOCK --->\n",
    "aug_x = x_preprocess(input_x)\n",
    "w_ls = calculate_map_coefficients(aug_x, output_y, 0,0) ##Least Squares Coefficients!!!\n",
    "sigma_squared = estimate_data_noise(aug_x, output_y, w_ls)\n",
    "\n",
    "w_map = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "S = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param)\n",
    "\n",
    "mu  = w_map\n",
    "big_sig = S\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 9",
     "locked": true,
     "points": "10",
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
