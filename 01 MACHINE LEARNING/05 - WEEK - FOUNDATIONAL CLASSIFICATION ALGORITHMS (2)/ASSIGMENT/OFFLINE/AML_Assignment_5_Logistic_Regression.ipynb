{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Logistic Regression  \n",
    "\n",
    "---------------\n",
    "\n",
    "_Authors: Khal Makhoul, W.P.G.Peterson_   \n",
    "\n",
    "## Project Guide\n",
    "------------\n",
    "- [Project Overview](#overview)\n",
    "- [Introduction and Review](#intro)\n",
    "- [Data Exploration](#data)\n",
    "- [Coding Logistic Regression](#code)\n",
    "- [Logistic Regression in sklearn](#sklearn)\n",
    "\n",
    "<a id = \"overview\"></a>\n",
    "## Project Overview  \n",
    "-------------\n",
    "#### EXPECTED TIME 3 HRS\n",
    "\n",
    "This assignment will work through the definition of a Logistic Regression function in `Python`. After a summary of the equations that will be used, and a brief EDA of the \"Titanic\" data we will be using, you will be asked to define a number of functions which will, in sum, create a Logistic Regression.  \n",
    "A demonstration of `sklearn`'s implementation of Logistic Regression will close the assignment.\n",
    "\n",
    "\n",
    "You will be asked to code functions to do the following:\n",
    "1. Implement the Logistic Regression Algorithm\n",
    "    - Calculate the value of the sigmoid function\n",
    "    - Calculate the gradient of the log-likelihood with respect to $w$\n",
    "    - Sum the gradients of the log-likelihood with respect to $w$\n",
    "2. Execute logistic regression, stopping after a particular iteration\n",
    "3. Determine convergence of the logistic regression algorithm\n",
    "\n",
    "**Motivation**: Logistic Regression offers a way to to create a fairly interpretable parametric model for binary classification.\n",
    "\n",
    "**Problem**: Using Logistic Regression, predict whether or not a passenger survived the sinking of the Titanic.\n",
    "\n",
    "**Data**: The data for today comes from [Kaggle's Titanic Data](https://www.kaggle.com/c/titanic/data). Please see above link for a more complete description of the data.\n",
    "\n",
    "\n",
    "<a id = \"intro\"></a>\n",
    "\n",
    "### Introduction and Review\n",
    "\n",
    "In this week lectures, we derived all of the equations that will be used in this assignment.  \n",
    "\n",
    "Recall that the likelihood for Logistic Regression is given by:\n",
    "\n",
    "$$p(y_1,\\ ...,\\ y_n\\ |\\ x_1,\\ ...,\\ x_n,\\ w)\\ =\\prod\\limits_{i=1}^n\\ \\sigma_i(y_i \\cdot w)$$  \n",
    "\n",
    "For coding purposes, we need the expression for the gradient of the log-likelihood $\\mathcal{L}$ with respect to $w$:\n",
    "\n",
    "\n",
    "$$\\nabla_w \\mathcal{L} = \\sum_{i = 1}^n (1 âˆ’ \\sigma_i(y_i \\cdot w))\\ y_i x_i$$  \n",
    "\n",
    "Where: $$\\sigma_i(y_i \\cdot w) = \\frac{e^{y_iX_i^Tw}}{1+e^{y_ix_i^Tw}}$$  \n",
    "\n",
    "\n",
    "<a id = \"data\"></a>\n",
    "### Data Exploration\n",
    "\n",
    "This assignment will analyze data from the Titanic passenger manifest. Demographic and trip information for each passenger is coupled with whether or not they survived the disaster.\n",
    "\n",
    "We start by examining the data as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules and sets a few plotting parameters for display\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "# Load the data into a `pandas` DataFrame object\n",
    "tr_path = '../resource/asnlib/publicdata/train.csv'\n",
    "titanic_df = pd.read_csv(tr_path)\n",
    "\n",
    "# Examine head of df\n",
    "titanic_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "# Load the data into a `pandas` DataFrame object\n",
    "tr_path = './train.csv'\n",
    "titanic_df = pd.read_csv(tr_path)\n",
    "\n",
    "# Examine head of df\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titanic_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "##NOTAR QUE: EN LA PROPIEDAD <.shape> EL NUMERO DE DIMENSIONES ES REGRESADO AL SER PASADA POR LA FUNCION <len()>\n",
    "my_array = np.arange(10)\n",
    "print(my_array.shape)\n",
    "print(len(my_array.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 1\n",
    " \n",
    "The exercise below requires dropping certain records / columns.  \n",
    "\n",
    "The general rules followed below are:  \n",
    "\n",
    "- If a column consists mostly of missing data, that column probably will not be of much use in prediction.  \n",
    "- If a column has very few missing values, and enough records to build a model are complete, the records with missing values in that column may be cast out.  \n",
    "\n",
    "The question statement below includes specific directions as to how to implement the above rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "col_name = ['dimension 1','dimension 2','dimension 3']\n",
    "new_df = pd.DataFrame(columns=col_name)\n",
    "print(len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension 1</th>\n",
       "      <th>dimension 2</th>\n",
       "      <th>dimension 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dimension 1  dimension 2  dimension 3\n",
       "0          0.3          0.0          0.0\n",
       "1          1.3          0.5          1.0\n",
       "2          2.3          1.0          4.0\n",
       "3          3.3          1.5          9.0\n",
       "4          4.3          2.0         16.0\n",
       "5          5.3          2.5         25.0\n",
       "6          6.3          3.0         36.0\n",
       "7          7.3          3.5         49.0\n",
       "8          8.3          4.0         64.0\n",
       "9          9.3          4.5         81.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d1 = i+0.3\n",
    "    d2 = i*0.5\n",
    "    d3 = i**2\n",
    "    new_df.loc[len(new_df)] = [d1, d2, d3]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([6, 7, 8, 9], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['dimension 1']>6].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##REMOVE THIS CELL?\n",
    "\n",
    "#Do not change this code\n",
    "\n",
    "def miss_data(df):\n",
    "    x = ['column_name','missing_data', 'missing_in_percentage']\n",
    "    missing_data = pd.DataFrame(columns=x)\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        icolumn_name = col\n",
    "        imissing_data = df[col].isnull().sum()\n",
    "        imissing_in_percentage = (df[col].isnull().sum()/df[col].shape[0])*100\n",
    "\n",
    "        missing_data.loc[len(missing_data)] = [icolumn_name, imissing_data, imissing_in_percentage]\n",
    "    print(missing_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    column_name missing_data  missing_in_percentage\n",
      "0   PassengerId            0               0.000000\n",
      "1      Survived            0               0.000000\n",
      "2        Pclass            0               0.000000\n",
      "3          Name            0               0.000000\n",
      "4           Sex            0               0.000000\n",
      "5           Age          177              19.865320\n",
      "6         SibSp            0               0.000000\n",
      "7         Parch            0               0.000000\n",
      "8        Ticket            0               0.000000\n",
      "9          Fare            0               0.000000\n",
      "10        Cabin          687              77.104377\n",
      "11     Embarked            2               0.224467\n"
     ]
    }
   ],
   "source": [
    "miss_data(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Embarked'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_df = titanic_df.drop(['Cabin'],axis=1)\n",
    "drop_df = drop_df.dropna(subset=['Embarked'])\n",
    "drop_df['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "shape",
     "locked": false,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### 1. Drop all of the columns in `titanic_df` that are filled more than 50% with nulls.\n",
    "### 2. If a column has fewer than 10 missing values, drop all of the records with missing data in that column.\n",
    "\n",
    "### After performing the above operations, what is the shape of the DataFrame?\n",
    "### Assign ints to the variables `row` and `cols` below corresponding to the *remaining* number of rows / columns.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "rows = 889\n",
    "cols = 11\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 1",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### How many values are missing from the column 'Age?'\n",
    "\n",
    "### Assign your answer to the variable ans1 as an integer.\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 177\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Given the fairly large number of values missing in the column \"Age\", and given that the age of a passenger is likely connected with the chances of survival of the passenger, we will create an educated guess for the missing missing values of the passengers' ages. In other words, we will impute the ages using a $k$-Nearest-Neighbor algorithm.\n",
    "\n",
    "Note: In imputing values for \"age\", becasue we want to predict the chances of survival of each passenger, the feature \"`survival`\" will be excluded from the $X$ matrix.\n",
    "\n",
    "#### KNeighborsRegressor in `sklearn`\n",
    "Because `sklearn` automatically converts all data to floats before fitting models, it is necessary to encode any categorical features will be using as dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop irrelevant features from the dataframe\n",
    "titanic_df.drop(['Ticket','Cabin', 'PassengerId', 'Name'], axis=1, inplace=True)\n",
    "titanic_df = titanic_df.loc[titanic_df['Embarked'].notnull(),:]\n",
    "\n",
    "### Drop \"Survived\" for purposes of KNN imputation:\n",
    "y_target = titanic_df.Survived\n",
    "titanic_knn = titanic_df.drop(['Survived'], axis = 1)  \n",
    "titanic_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  22.0      1      0   7.2500         1           0           1\n",
       "1       1  38.0      1      0  71.2833         0           0           0\n",
       "2       3  26.0      0      0   7.9250         0           0           1\n",
       "3       1  35.0      1      0  53.1000         0           0           1\n",
       "4       3  35.0      0      0   8.0500         1           0           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adding dummy variables for categorical variables\n",
    "to_dummy = ['Sex','Embarked']\n",
    "titanic_knn = pd.get_dummies(titanic_knn, prefix = to_dummy, columns = to_dummy, drop_first = True)\n",
    "\n",
    "titanic_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Impute\n",
      "    Pclass  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
      "5        3      0      0   8.4583         1           1           0\n",
      "17       2      0      0  13.0000         1           0           1\n",
      "19       3      0      0   7.2250         0           0           0\n",
      "\n",
      "Imputed Ages\n",
      "    Pclass  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S   Age\n",
      "5        3      0      0   8.4583         1           1           0  47.2\n",
      "17       2      0      0  13.0000         1           0           1  25.6\n",
      "19       3      0      0   7.2250         0           0           0  23.0\n",
      "Shape before imputation: (889, 8)\n",
      "Shape with imputed values: (889, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>47.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  22.0      1      0   7.2500         1           0           1\n",
       "1       1  38.0      1      0  71.2833         0           0           0\n",
       "2       3  26.0      0      0   7.9250         0           0           1\n",
       "3       1  35.0      1      0  53.1000         0           0           1\n",
       "4       3  35.0      0      0   8.0500         1           0           1\n",
       "5       3  47.2      0      0   8.4583         1           1           0\n",
       "6       1  54.0      0      0  51.8625         1           0           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Splitting data - on whether or not \"Age\" is specified.\n",
    "\n",
    "# Training data -- \"Age\" Not null; \"Age\" as target\n",
    "train = titanic_knn[titanic_knn.Age.notnull()]\n",
    "X_train = train.drop(['Age'], axis = 1)\n",
    "y_train = train.Age\n",
    "\n",
    "\n",
    "# Data to impute, -- Where Age is null; Remove completely-null \"Age\" column.\n",
    "impute = titanic_knn[titanic_knn.Age.isnull()].drop(['Age'], axis = 1)\n",
    "print(\"Data to Impute\")\n",
    "print(impute.head(3))\n",
    "\n",
    "# import algorithm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instantiate\n",
    "knr = KNeighborsRegressor()\n",
    "\n",
    "# Fit\n",
    "knr.fit(X_train, y_train)\n",
    "\n",
    "# Create Predictions\n",
    "imputed_ages = knr.predict(impute)\n",
    "\n",
    "# Add to Df\n",
    "impute['Age'] = imputed_ages\n",
    "print(\"\\nImputed Ages\")\n",
    "print(impute.head(3))\n",
    "\n",
    "# Re-combine dataframes\n",
    "titanic_imputed = pd.concat([train, impute], sort = False, axis = 0)\n",
    "\n",
    "# Return to original order - to match back up with \"Survived\"\n",
    "titanic_imputed.sort_index(inplace = True)\n",
    "print(\"Shape before imputation:\", titanic_knn.shape)\n",
    "print(\"Shape with imputed values:\", titanic_imputed.shape)\n",
    "titanic_imputed.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It would be appropriate to spend more time taking care with the imputation of age. In fact, missing data can introduce a substantial amount of bias, make the handling and analysis of the data more arduous, and create reductions in efficiency. For brevity's sake, this will not be done here.\n",
    "\n",
    "#### Brief EDA\n",
    "\n",
    "First, let's look at tabulations of categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All combinations of categorical variables: \n",
      " [('Pclass', 'Sex'), ('Pclass', 'Embarked'), ('Sex', 'Embarked')] \n",
      "\n",
      "Row Percents: \n",
      " Sex       female      male\n",
      "Pclass                    \n",
      "1       0.429907  0.570093\n",
      "2       0.413043  0.586957\n",
      "3       0.293279  0.706721 \n",
      "\n",
      "Column Percents: \n",
      " Sex       female      male\n",
      "Pclass                    \n",
      "1       0.294872  0.211438\n",
      "2       0.243590  0.187175\n",
      "3       0.461538  0.601386 \n",
      "---------------\n",
      "\n",
      "Row Percents: \n",
      " Embarked         C         Q         S\n",
      "Pclass                                \n",
      "1         0.397196  0.009346  0.593458\n",
      "2         0.092391  0.016304  0.891304\n",
      "3         0.134420  0.146640  0.718941 \n",
      "\n",
      "Column Percents: \n",
      " Embarked         C         Q         S\n",
      "Pclass                                \n",
      "1         0.505952  0.025974  0.197205\n",
      "2         0.101190  0.038961  0.254658\n",
      "3         0.392857  0.935065  0.548137 \n",
      "---------------\n",
      "\n",
      "Row Percents: \n",
      " Embarked         C         Q         S\n",
      "Sex                                   \n",
      "female    0.233974  0.115385  0.650641\n",
      "male      0.164645  0.071057  0.764298 \n",
      "\n",
      "Column Percents: \n",
      " Embarked         C         Q         S\n",
      "Sex                                   \n",
      "female    0.434524  0.467532  0.315217\n",
      "male      0.565476  0.532468  0.684783 \n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# Lists of categorical v. numeric features\n",
    "categorical = ['Pclass','Sex','Embarked']\n",
    "numeric = ['Age','SibSp','Parch','Fare']\n",
    "\n",
    "# Create all pairs of categorical variables and look at the distributions\n",
    "cat_combos = list(itertools.combinations(categorical, 2))\n",
    "print(\"All combinations of categorical variables: \\n\",cat_combos, \"\\n\")\n",
    "for row, col in cat_combos:\n",
    "    print(\"Row Percents: \\n\",pd.crosstab(titanic_df[row], titanic_df[col], normalize=\"index\"), \"\\n\")\n",
    "    print(\"Column Percents: \\n\", pd.crosstab(titanic_df[row], titanic_df[col], normalize=\"columns\"),\"\\n---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**For the numeric variables, we simply created a correlation heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(titanic_df[numeric].corr(), cmap = \"coolwarm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### True or False:\n",
    "### Other than the autocorrelation, two of the above variables in the heatmap\n",
    "### have a correlation that is greater than 0.5?\n",
    "\n",
    "### Assign your answer as a boolean value ans3\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans3 = False\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 3",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"code\"></a>\n",
    "### Coding Logistic Regression\n",
    "\n",
    "The first function we will be coding will perform the pre-processing of our data. \n",
    "\n",
    "Define a function called `prepare_data` that takes, as arguments, `numpy` arrays `input_x` and `target_y`.\n",
    "Your function should perform the following steps:\n",
    "\n",
    "**First**: Ensure that the `input_x` and `target_y` arrays  have the observations as rows, and features as columns. In particular:\n",
    "- `input_x` should be a matrix with $n$ rows and $d$ columns. Where $n>d$\n",
    "- `target_y` should be a 1-dimensional numpy array of length $n$.  \n",
    "\n",
    "**Second**: A column of ones must be added to `input_x` matrix, increasing its dimensions to $ n \\times d+1$.  \n",
    "\n",
    "**Third**: Ensure that `target_y` has all values encoded as 1 and -1, **not** 1 and 0.  \n",
    "\n",
    "**Fourth**: The initial  weights must be created as a zero vector of length $d+1$ (Hint: look at the function `np.zeros`)\n",
    "\n",
    "Your function should return three arrays `return prepared_x, prepared_y, initial_w`, each created following the steps above.\n",
    "\n",
    "The example below shows how to return multiple items within the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1 b: 2 c: 3 z: (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "def ex_func(): return 1,2,3\n",
    "\n",
    "\n",
    "z = ex_func()\n",
    "a,b,c = ex_func()\n",
    "\n",
    "print(\"a:\", a,\"b:\",b,\"c:\",c,\"z:\",z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_x, target_y):\n",
    "    ##Data Validation: X_nxp, Where n>>p & y_nx1 ...\n",
    "    if input_x.shape[0] < input_x.shape[1]:\n",
    "        input_x = input_x.T\n",
    "    \n",
    "    if len(target_y.shape) > 1:\n",
    "        if min(target_y.shape) == 1:\n",
    "            target_y.reshape(-1) #Reshape target_y into a vector\n",
    "        else:\n",
    "            print('Vector target_y has wrong dimensions')\n",
    "        \n",
    "    ##Append one's column in X for Intercepto Estimation ...\n",
    "    betta = np.ones(input_x.shape[0],dtype = int).T\n",
    "    input_x = np.insert(input_x, 0, betta, axis = 1)\n",
    "    \n",
    "    ##Replace any zero value in target_y vector with -1.0 ...\n",
    "    target_y[target_y == 0] = -1\n",
    "    \n",
    "    ##Generate initial weights ...\n",
    "    initial_w = np.zeros(input_x.shape[1])\n",
    "    \n",
    "    return input_x, target_y, initial_w \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1 11]\n",
      " [ 1  2 12]\n",
      " [ 1  3 13]\n",
      " [ 1  4 14]]\n",
      "[ 1 -1  1  1]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3,4],[11,12,13,14]])\n",
    "y = np.array([1,0,1,1])\n",
    "x,y,w = prepare_data(x,y)\n",
    "\n",
    "print(x) #--> array([[ 1,  1, 11],\n",
    "#                     [ 1,  2, 12],\n",
    "#                     [ 1,  3, 13],\n",
    "#                     [ 1,  4, 14]])\n",
    "\n",
    "print(y) #--> array([1, -1, 1, 1])\n",
    "\n",
    "print(w) #--> array([0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Define `prepare_data` using the instructions given above\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def prepare_data(input_x, target_y):\n",
    "    \"\"\"\n",
    "    Confirm dimensions of x and y, transpose if appropriate;\n",
    "    Add column of ones to x;\n",
    "    Ensure y consists of 1's and -1's;\n",
    "    Create weights array of all 0s\n",
    "    \n",
    "    Return X, y, and weights.\n",
    "    \n",
    "    Arguments:\n",
    "        input_x - a numpy array \n",
    "        target_y - a numpy array\n",
    "        \n",
    "    Returns:\n",
    "        prepared_x -- a 2-d numpy array; first column consists of 1's,\n",
    "            more rows than columns\n",
    "        prepared_y -- a numpy array consisting only of 1s and -1s\n",
    "        initial_w -- a 1-d numpy array consisting of \"d+1\" 0s, where\n",
    "            \"d+1\" is the number of columns in \"prepared_x\"\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[1,2,3,4],[11,12,13,14]])\n",
    "        y = np.array([1,0,1,1])\n",
    "        x,y,w = prepare_data(x,y)\n",
    "        \n",
    "        print(x) #--> array([[ 1,  1, 11],\n",
    "                            [ 1,  2, 12],\n",
    "                            [ 1,  3, 13],\n",
    "                            [ 1,  4, 14]])\n",
    "                            \n",
    "        print(y) #--> array([1, -1, 1, 1])\n",
    "        \n",
    "        print(w) #--> array([0., 0., 0.])\n",
    "        \n",
    "    Assumptions:\n",
    "        Assume that there are more observations than features in `input_x`\n",
    "    \"\"\" \n",
    "    ##Data Validation: X_nxp, Where n>>p & y_nx1 ...\n",
    "    if input_x.shape[0] < input_x.shape[1]:\n",
    "        input_x = input_x.T\n",
    "    \n",
    "    if len(target_y.shape) > 1:\n",
    "        if min(target_y.shape) == 1:\n",
    "            target_y.reshape(-1) #Reshape target_y into a vector\n",
    "        else:\n",
    "            print('Vector target_y has wrong dimensions')\n",
    "        \n",
    "    ##Append one's column in X for Intercepto Estimation ...\n",
    "    betta = np.ones(input_x.shape[0],dtype = int).T\n",
    "    input_x = np.insert(input_x, 0, betta, axis = 1)\n",
    "    \n",
    "    ##Replace any zero value in target_y vector with -1.0 ...\n",
    "    target_y[target_y == 0] = -1\n",
    "    \n",
    "    ##Generate initial weights ...\n",
    "    initial_w = np.zeros(input_x.shape[1])\n",
    "    \n",
    "    return input_x, target_y, initial_w \n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3,4],[11,12,13,14]])\n",
    "y = np.array([1,0,1,1])\n",
    "#y = np.array([[1],[0],[1],[1]])\n",
    "x,y,w = prepare_data(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1,  1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 4",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 5\n",
    "Next, we will define a function to calculate the value of the sigmoid. \n",
    "\n",
    "Recall that the equation for the sigmoid is given by:\n",
    "$$\\sigma_i(y_i \\cdot w) = \\frac{e^{y_iX_i^Tw}}{1+e^{y_ix_i^Tw}}$$  \n",
    "\n",
    "Define a function called `sigmoid_single` that takes, as arguments, the arrays $x_i$, $y_i$, and $w$ and returns the sigmoid, as a float, with value between 0 and 1.  \n",
    "\n",
    "Hint: First calculate $e^{y_ix_i^Tw}$; use `np.exp()`.  \n",
    "\n",
    "Look closely at the examples below.  \n",
    "$e^{y_ix_i^Tw}$ will evaluate to $np.inf$ if $y_ix_i^Tw$ is greater than ~709.782. In this case, a `\"1\"` should be returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_single(x, y, w):\n",
    "    '''Arguments:\n",
    "        x - a vector of length d\n",
    "        y - either 1, or -1\n",
    "        w - a vector of length d'''\n",
    "    e = np.exp(y * np.matmul(x.T,w))\n",
    "    \n",
    "    ##Validate e is not +infinity ...\n",
    "    if e == np.inf:\n",
    "        return 1\n",
    "    else:\n",
    "        return e/(1 + e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002034269780552065\n"
     ]
    }
   ],
   "source": [
    "x = np.array([23.0,75])\n",
    "y = -1\n",
    "w = np.array([2,-.5])\n",
    "sig = sigmoid_single(x, y, w)\n",
    "\n",
    "print(sig) #--> 0.0002034269780552065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x2 = np.array([ 1. , 22., 0. , 1. , 7.25 , 0. , 3. , 1. , 1.])\n",
    "w2 = np.array([ -10.45 , -376.7215 , -0.85, -10.5 , 212.425475 , -1.1, -36.25 , -17.95 , -7.1])\n",
    "y2 = -1\n",
    "sig2 = sigmoid_single(x2,y2,w2)\n",
    "\n",
    "print(sig2) #--> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow the directions given above\n",
    "### YOUR ANSWER BELOW\n",
    "def sigmoid_single(x, y, w):\n",
    "    \"\"\"\n",
    "    Obtain the value of a Sigmoid using training data.\n",
    "    \n",
    "    Arguments:\n",
    "        x - a vector of length d\n",
    "        y - either 1, or -1\n",
    "        w - a vector of length d\n",
    "    \n",
    "    Example:\n",
    "        x = np.array([23.0,75])\n",
    "        y = -1\n",
    "        w = np.array([2,-.5])\n",
    "        sig = sigmoid_single(x, y, w)\n",
    "        \n",
    "        print(sig) #--> 0.0002034269780552065\n",
    "        \n",
    "        x2 = np.array([ 1. , 22., 0. , 1. , 7.25 , 0. , 3. , 1. , 1.])\n",
    "        w2 = np.array([ -10.45 , -376.7215 , -0.85, -10.5 , 212.425475 , -1.1, -36.25 , -17.95 , -7.1])\n",
    "        y2 = -1\n",
    "        sig2 = sigmoid_single(x2,y2,w2)\n",
    "        \n",
    "        print(sig2) #--> 1\n",
    "    \"\"\"\n",
    "    e = np.exp(y * np.matmul(x.T,w))\n",
    "    \n",
    "    ##Validate e is not +infinity ...\n",
    "    if e == np.inf:\n",
    "        return 1\n",
    "    else:\n",
    "        return e/(1 + e)\n",
    "    \n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array([ 1. , 22., 0. , 1. , 7.25 , 0. , 3. , 1. , 1.])\n",
    "w2 = np.array([ -10.45 , -376.7215 , -0.85, -10.5 , 212.425475 , -1.1, -36.25 , -17.95 , -7.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6902.53830625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.dot(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6902.53830625"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.T@w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 5",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 6\n",
    "With the sigmoid, $\\sigma_i(y_i \\cdot w)$ defined above, we can define the rest of the function that is summed to calculate the gradient of the log-likelihood.   \n",
    "\n",
    "Define a function named `to_sum` that takes, as input,  two vectors of length d, $x_i$ and $w_i$, and the paramenter $y$ equal to either 1, or -1. Your function will eventually be summed to find the gradient of the log-likelihood. \n",
    "Your function should return the value of $(1-\\sigma_i(y_i\\cdot w))y_ix_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sum(x,y,w):\n",
    "    dsig = 1 - sigmoid_single(x,y,w)\n",
    "    \n",
    "    return dsig * y * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.01756737e-05 -2.28833719e-04]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([23.0,75])\n",
    "y = -1\n",
    "w = np.array([.1,-.2])\n",
    "print(to_sum(x,y,w)) # --> array([-7.01756737e-05, -2.28833719e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### YOUR ANSWER BELOW\n",
    "def to_sum(x,y,w):\n",
    "    \"\"\"\n",
    "    Obtain the value of the function that will eventually be summed to \n",
    "    find the gradient of the log-likelihood.\n",
    "    \n",
    "    Arguments:\n",
    "        x - a vector of length d\n",
    "        y - either 1, or -1\n",
    "        w - a vector of length d\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([23.0,75])\n",
    "        y = -1\n",
    "        w = np.array([.1,-.2])\n",
    "        print(to_sum(x,y,w)) # --> array([-7.01756737e-05, -2.28833719e-04])\n",
    "    \n",
    "    \"\"\"\n",
    "    dsig = 1 - sigmoid_single(x,y,w)\n",
    "    return dsig * y * x\n",
    "\n",
    "    # Use function created above, multiply by x and y arrays.\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 6",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 7\n",
    "Finally, code a function called `sum_all` that will obtain and return the gradient of the log-likelihood.  \n",
    "Your function shoudl take the pre-processed matricies corresponding to `X`, `y`, and the weights,  and should return\n",
    "$\\sum_{i = 1}^n (1 âˆ’ \\sigma_i(y_i \\cdot w))\\ y_i x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_all(x_input, y_target, w):\n",
    "    ##Initialize Summation ...\n",
    "    Sigma = np.zeros(w.shape[0])\n",
    "    \n",
    "    ##Getting a single observation and its label ...\n",
    "    for x, y in zip(x_input, y_target):\n",
    "        Sigma += to_sum(x,y,w)\n",
    "        \n",
    "    return Sigma        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33737816 -7.42231958 -2.44599168]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "y = np.array([-1,1])\n",
    "w = np.array([.1,-.2, .5])\n",
    "print(sum_all(x,y,w)) #--> array([-0.33737816, -7.42231958, -2.44599168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow instructions above\n",
    "### YOUR ANSWER BELOW\n",
    "def sum_all(x_input, y_target, w):\n",
    "    \"\"\"\n",
    "    Obtain and return the gradient of the log-likelihood\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *preprocessed* an array of shape n-by-d\n",
    "        y_target - *preprocessed* a vector of length n\n",
    "        w - a vector of length d\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "        y = np.array([-1,1])\n",
    "        w = np.array([.1,-.2, .5])\n",
    "        print(sum_all(x,y,w)) #--> array([-0.33737816, -7.42231958, -2.44599168]) \n",
    "    \"\"\"\n",
    "    ##Initialize Summation ...\n",
    "    Sigma = np.zeros(w.shape[0])\n",
    "    \n",
    "    ##Getting a single observation and its label ...\n",
    "    for x, y in zip(x_input, y_target):\n",
    "        Sigma += to_sum(x,y,w)\n",
    "        \n",
    "    return Sigma\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 7",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 8\n",
    "Code a function called `update_w`, that performs a single-step of gradient descent for calculating the Logistic Regression weights.\n",
    "\n",
    "Your function should take, as inputs, the pre-processed arrays `input_x` and `target_y`, the current weights $w$ and $\\eta$, a positive float with value close to zero.\n",
    "The function `update_w` should return:\n",
    "$$w_i + \\eta \\sum_{i = 1}^n (1 âˆ’ \\sigma_i(y_i \\cdot w_i))\\ y_i x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_w(x_input, y_target, w, eta):\n",
    "    \n",
    "    return w + eta * sum_all(x_input,y_target,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06626218 -0.94223196  0.25540083]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "y = np.array([-1,1])\n",
    "w = np.array([.1,-.2, .5])\n",
    "eta = .1\n",
    "\n",
    "print(update_w(x,y,w, eta)) #--> array([ 0.06626218, -0.94223196,  0.25540083])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### YOUR ANSWER BELOW\n",
    "def update_w(x_input, y_target, w, eta):\n",
    "    \"\"\"Obtain and return updated Logistic Regression weights\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *preprocessed* an array of shape n-by-d\n",
    "        y_target - *preprocessed* a vector of length n\n",
    "        w - a vector of length d\n",
    "        eta - a float, positive, close to 0\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "        y = np.array([-1,1])\n",
    "        w = np.array([.1,-.2, .5])\n",
    "        eta = .1\n",
    "        \n",
    "        print(update_w(x,y,w, eta)) #--> array([ 0.06626218, -0.94223196,  0.25540083])\n",
    "\"\"\"\n",
    "    return w + eta * sum_all(x_input,y_target,w)\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 8",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 9\n",
    "Next, create a function called `fixed_iteration` which will perform gradient descent, calculating the Logistic Regression weights for a specified number of steps.  \n",
    "\n",
    "\n",
    "Your function should take *Un-preprocessed* `x`- and `y`- matricies, an $\\eta$ parameter, a positive float close to 0, `steps`, an integer defining the number of steps.\n",
    "\n",
    "The function `fixed_iteration` should return $w_{steps}$, the weights calculated from 'steps' number of steps of gradient descent, where \n",
    "\n",
    "$$w_{i+1} = w_i + \\eta \\sum_{i = 1}^n (1 âˆ’ \\sigma_i(y_i \\cdot w_i))\\ y_i x_i$$\n",
    "\n",
    "NB: Initial weights ($w_0$) should all be 0's like are returned from the `prepare_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_iteration(x_input, y_target, eta, steps):\n",
    "    \n",
    "    ##Preprocess data and get initial weights ...\n",
    "    X, y, w = prepare_data(x_input, y_target)\n",
    "    \n",
    "    ##Update weights N steps ...\n",
    "    for step in range(steps):\n",
    "        w = update_w(X, y, w, eta)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9742495  -0.41389924  6.8199374 ]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "y = np.array([-1,1,1,1])\n",
    "eta = .1\n",
    "steps = 100\n",
    "\n",
    "print(fixed_iteration(x,y, eta, steps)) #--> np.array([-0.9742495,  -0.41389924, 6.8199374 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow the directions given above\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def fixed_iteration(x_input, y_target, eta, steps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return weights calculated from 'steps' number of steps of gradient descent.\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *NOT-preprocessed* an array\n",
    "        y_target - *NOT-preprocessed* a vector of length n\n",
    "        eta - a float, positve, close to 0\n",
    "        steps - an int\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "        y = np.array([-1,1,1,1])\n",
    "        eta = .1\n",
    "        steps = 100\n",
    "        \n",
    "        print(fixed_iteration(x,y, eta, steps)) #--> np.array([-0.9742495,  -0.41389924, 6.8199374 ])\n",
    "    \"\"\"\n",
    "    ##Preprocess data and get initial weights ...\n",
    "    X, y, w = prepare_data(x_input, y_target)\n",
    "    \n",
    "    ##Update weights N steps ...\n",
    "    for step in range(steps):\n",
    "        w = update_w(X, y, w, eta)\n",
    "    \n",
    "    return w\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 9",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 10\n",
    "For the final function, we will create prediction for out-of-sample data.  \n",
    "\n",
    "Code a function called \"`predict`\" that accept, as inputs, an **un-preprocessed** numpy array `input_x` with the observations and the array `weights` containing the weight. Your function should return a label prediction of `input_x` observations; either -1 or 1 (integers).  \n",
    "\n",
    "**Hint** *FIRST* preprocess `input_x`. Then; If `input_x`$^T\\cdot w > 0$  predict 1. Otherwise, predict -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_input, weights):\n",
    "    ##NOTE: x_input - *NOT-preprocessed* a vector of length d-1\n",
    "    x_augmented = np.insert(x_input, 0, 1)\n",
    "    \n",
    "    ##Label Prediction y` = 1, if (x^T * w) > 0 ...\n",
    "    y_hat = np.matmul(x_augmented.T,weights)\n",
    "    \n",
    "    if y_hat > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "Xs = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "weights = np.array([0,1,-1])\n",
    "\n",
    "for X in Xs:\n",
    "    print(predict(X,weights))\n",
    "#     #-->     1\n",
    "#             -1\n",
    "#              1\n",
    "#             -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow the directions given above\n",
    "### YOUR ANSWER BELOW\n",
    "def predict(x_input, weights):\n",
    "    \"\"\"\n",
    "    Return the label prediction, 1 or -1 (an integer), for the given x_input and LR weights.\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *NOT-preprocessed* a vector of length d-1\n",
    "        weights - a vector of length d\n",
    "               \n",
    "    Example:\n",
    "        Xs = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "        weights = np.array([0,1,-1])\n",
    "        \n",
    "        for X in Xs:\n",
    "            print(predict(X,weights))\n",
    "            #-->     1\n",
    "                    -1\n",
    "                     1\n",
    "                    -1\n",
    "    \"\"\"\n",
    "    ##NOTE: x_input - *NOT-preprocessed* a vector of length d-1\n",
    "    x_augmented = np.insert(x_input, 0, 1)\n",
    "    \n",
    "    ##Label Prediction y` = 1, if (x^T * w) > 0 ...\n",
    "    y_hat = np.matmul(x_augmented.T,weights)\n",
    "    \n",
    "    if y_hat > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"sklearn\"></a>\n",
    "### Logistic Regression in `sklearn`\n",
    "\n",
    "The following cells will demonstrate Logistic Regression using `sklearn`, and compare the custom Logistic Regression built in the previous functions to `sklearn's`\n",
    "\n",
    "For a more complete description of how to perfor Logistic Regression in `sklearn` you can visit [Logistic Regression in `sklearn` - Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.07454295]\n",
      "[[-0.88163975 -0.03085442 -0.29522779 -0.0771424   0.00431432 -2.40900801\n",
      "   0.08754859 -0.21682785]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(titanic_imputed, y_target)\n",
    "\n",
    "# Create sklearn's predictions\n",
    "sk_pred = lr.predict(titanic_imputed)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If the above functions are correctly defined, the below cell should work.\n",
    "Because the regularization is implemented in the `sklearn` instantiation, the particular coefficients will be very different, however the signs should be mostly the same. Make sure that custom version coded above has a similar result to the one given by `sklearn`.\n",
    "\n",
    "**FOR FASTER GRADING TRY COMMENTING OUT THE BELOW CELLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_imputed.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# This cell may take awhile\n",
    "logr_w = fixed_iteration(titanic_imputed.values, y_target.values, .01, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.04324874, -50.47489277, -24.22255619, -87.68857616,\n",
       "       -25.58676257,  49.43086102, -88.89344389,   7.8406932 ,\n",
       "       -21.37851355])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "[  6853.75182849   -831.23291018   -304.24383135  -2919.42190116\n",
      "  -1291.68658091    218.83793151 -14297.98042097     66.49415552\n",
      "    428.14909561]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# # This cell may take awhile\n",
    "wt = fixed_iteration(titanic_imputed.values, y_target.values, .05, 12000)\n",
    "\n",
    "print(wt)\n",
    "\n",
    "cust_preds = np.array([predict(x,wt) for x in titanic_imputed.values])\n",
    "cust_preds[cust_preds == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hats = np.array([predict(x,logr_w) for x in titanic_imputed.values])\n",
    "# y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       549\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.77      0.69      0.73       340\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       889\n",
      "   macro avg       0.26      0.23      0.24       889\n",
      "weighted avg       0.30      0.26      0.28       889\n",
      "\n",
      "Custom:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       549\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.82      0.41      0.54       340\n",
      "\n",
      "   micro avg       0.16      0.16      0.16       889\n",
      "   macro avg       0.27      0.14      0.18       889\n",
      "weighted avg       0.31      0.16      0.21       889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"sklearn:\")\n",
    "print(classification_report(y_target, sk_pred))\n",
    "\n",
    "print(\"Custom:\")\n",
    "print(classification_report(y_target, cust_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
